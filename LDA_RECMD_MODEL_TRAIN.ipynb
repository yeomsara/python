{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:11:47.362483Z",
     "start_time": "2021-01-16T01:11:47.357183Z"
    }
   },
   "source": [
    "loading libraries and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:28:11.470475Z",
     "start_time": "2021-03-15T01:27:39.220876Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## 함수 로딩  \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time \n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import calendar\n",
    "import argparse\n",
    "\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from tqdm.contrib.concurrent import process_map  # or thread_map\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "import logging # This allows for seeing if the model converges. A log file is created.\n",
    "import pickle\n",
    "import subprocess\n",
    "import numexpr as ne\n",
    "import psutil\n",
    "import shutil\n",
    "\n",
    "## 전처리 모듈\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from itertools import chain\n",
    "\n",
    "## Gensim 모듈\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "## SQL & Connection 모듈\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import types\n",
    "from sqlalchemy import inspect\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String, Numeric\n",
    "from hdbcli import dbapi\n",
    "import configparser \n",
    "\n",
    "## 후처리 모듈\n",
    "import re\n",
    "import os\n",
    "from functools import reduce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:28:11.503781Z",
     "start_time": "2021-03-15T01:28:11.501604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world! Your pid is : 191894\n"
     ]
    }
   ],
   "source": [
    "## 현재 pid 확인\n",
    "print(\"Hello world! Your pid is :\", os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:28:11.526777Z",
     "start_time": "2021-03-15T01:28:11.524712Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',100,'display.max_columns',100)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ArgParse 대상날짜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:28:11.555446Z",
     "start_time": "2021-03-15T01:28:11.552158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of 2021-03-15 , check model update schedule..\n"
     ]
    }
   ],
   "source": [
    "model_dev_start_date = datetime.datetime.now()\n",
    "model_dev_start_date = model_dev_start_date.strftime('%Y-%m-%d')\n",
    "print(\"As of\",model_dev_start_date, \", check model update schedule..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:28:11.567059Z",
     "start_time": "2021-03-15T01:28:11.558277Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--target_date TARGET_DATE]\n",
      "                             [--trainig_days TRAINIG_DAYS]\n",
      "                             [--n_worker N_WORKER] [--n_pass N_PASS]\n",
      "                             [--manual_update MANUAL_UPDATE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1001/jupyter/kernel-f82cadea-2565-4018-b08c-6d3a3eced4ec.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "## -----------------------------------------\n",
    "# parse init args\n",
    "## -----------------------------------------\n",
    "parser = argparse.ArgumentParser(description = 'LDA Recommender System Dev Query')\n",
    "parser.add_argument('--target_date', \n",
    "                    help = '초도 모델을 개발할 데이터의 날짜를 지정할 때 사용')\n",
    "parser.add_argument('--trainig_days', \n",
    "                    help = '모델 개발 시, 몇 일 치 데이터를 업데이트할 것인지 지정')\n",
    "parser.add_argument('--n_worker', \n",
    "                    help = '모델 개발 시, 몇 개의 multiprocesser core 를 사용할 것인지 지정')\n",
    "parser.add_argument('--n_pass', \n",
    "                    help = '모델 개발 시, EM 알고리즘의 몇 번의 M-Step 을 거칠 것인지 지정')\n",
    "parser.add_argument('--manual_update', \n",
    "                    help = 'y/n 으로 설정. 기 설정된 모델업데이트 로직을 무시하고 지정된 target_date 로 모델을 수행할 것인지 지정')\n",
    "args = parser.parse_args()\n",
    "\n",
    "try : \n",
    "    target_date = args.target_date\n",
    "except : \n",
    "    target_date = None\n",
    "    \n",
    "try : \n",
    "    training_days = args.training_days\n",
    "except: \n",
    "    training_days = None\n",
    "    \n",
    "try : \n",
    "    n_worker = args.n_worker\n",
    "except : \n",
    "    n_worker = None\n",
    "    \n",
    "try : \n",
    "    n_pass = args.n_pass\n",
    "except : \n",
    "    n_pass = None\n",
    "\n",
    "try : \n",
    "    manual_update = args.manual_update\n",
    "except : \n",
    "    manual_update = None\n",
    "\n",
    "\n",
    "# Target-date setting     \n",
    "if (target_date == None) | (target_date == 'None') :\n",
    "    start_time  = datetime.datetime.now()\n",
    "    target_date = (start_time - datetime.timedelta(days = 5)).strftime('%Y-%m-%d')\n",
    "    # default 로 D-1 일 기준 4일 전 데이터를 활용하여 초도 모델 개발 세팅\n",
    "\n",
    "# Training-days setting\n",
    "if (training_days == None) | (training_days == 'None') :\n",
    "    training_days = 3 # default 로 초도모델 개발 이후 3일치 데이터를 활용하여 모델 업데이트 세팅\n",
    "else : \n",
    "    training_days = int(training_days)\n",
    "\n",
    "# multiprocessing core setting    \n",
    "if (n_worker == None) | (n_worker == 'None') :\n",
    "    n_worker = 20 # defualt 로 20개의 multiprocess cpu 를 사용\n",
    "else : \n",
    "    n_worker = int(n_worker)\n",
    "\n",
    "# M-step iteration number setting\n",
    "if (n_pass == None) | (n_pass == 'None') :\n",
    "    n_pass = 30 # default 로 30 번의 M-step 을 거치도록 설정\n",
    "else : \n",
    "    n_pass = int(n_pass)\n",
    "\n",
    "# (21.01.26 updates) 스크립트에 내장된 model_update_interpreter 를 무시하고 target_date 기준으로 모델을 수행할 것인지 설정\n",
    "if (manual_update == None) | (manual_update == 'None') : \n",
    "    manual_update = 'n' ## defualt 는 N 으로 설정\n",
    "else : \n",
    "    manual_update = str(manual_update)\n",
    "\n",
    "\n",
    "    \n",
    "print(\"================================================\")\n",
    "print(\"============= Argument setting =================\")\n",
    "print(\"current_date : \",model_dev_start_date,\n",
    "      \"\\ntarget_date : \",target_date,\n",
    "      \"\\ntraining_days : \",training_days,\n",
    "      \"\\nn_worker : \",n_worker,\n",
    "      \"\\nn_pass : \",n_pass, \n",
    "      \"\\nignore in-built update schedule : \", manual_update, sep=\"\")\n",
    "print(\"================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:28:11.570238Z",
     "start_time": "2021-03-15T01:27:40.915Z"
    }
   },
   "outputs": [],
   "source": [
    "# target_date = '2020-12-29'\n",
    "# training_days = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:58:12.873850Z",
     "start_time": "2021-03-15T01:58:12.869001Z"
    }
   },
   "outputs": [],
   "source": [
    "target_date_6digits = datetime.datetime.strptime(target_date, '%Y-%m-%d').strftime('%y%m%d')\n",
    "# print(target_date, \"(\",target_date_6digits,\")\",\"th operation is getting started..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T05:18:07.830139Z",
     "start_time": "2021-01-27T05:18:07.816048Z"
    }
   },
   "outputs": [],
   "source": [
    "## -----------------------------------------\n",
    "## 초도 모델 개발 이후 업데이트 기간 설정\n",
    "## -----------------------------------------\n",
    "\n",
    "start_date = datetime.datetime.strptime(target_date, '%Y-%m-%d') + timedelta(days = 1)\n",
    "end_date = datetime.datetime.strptime(target_date, '%Y-%m-%d') + timedelta(days = training_days)\n",
    "step = datetime.timedelta(days=1)\n",
    "\n",
    "date_list = []\n",
    "while start_date <= end_date:\n",
    "    date_list.append(start_date.strftime('%Y-%m-%d'))\n",
    "    start_date += step\n",
    "    \n",
    "## dictionary 형태로 변형\n",
    "day_dict = []\n",
    "for i in date_list :\n",
    "    day_dict += [{'from':i, 'to':i}]\n",
    "\n",
    "print(\"Scheduled update period starts from to end according to training_days after target_date :\") \n",
    "display(day_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T05:28:43.225991Z",
     "start_time": "2021-03-17T05:28:41.964118Z"
    }
   },
   "outputs": [],
   "source": [
    "conf_dir = '/home/cdsadmin/AMT/src/conf/config.ini'\n",
    "cfg = configparser.ConfigParser(interpolation=configparser.ExtendedInterpolation())\n",
    "cfg.read(conf_dir)\n",
    "\n",
    "global HOST,PORT,DB_ID,DB_PW\n",
    "\n",
    "HOST = cfg['dbconnect']['host']\n",
    "PORT = int(cfg['dbconnect']['port'])\n",
    "DB_ID = cfg['dbconnect']['ID']\n",
    "DB_PW = cfg['dbconnect']['PW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:34:59.100964Z",
     "start_time": "2021-03-15T01:34:58.145732Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql hana+hdbcli://{DB_ID}:{DB_PW}@{HOST}:{PORT}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:34:59.133705Z",
     "start_time": "2021-03-15T01:34:59.129994Z"
    },
    "code_folding": [
     0,
     4,
     11
    ]
   },
   "outputs": [],
   "source": [
    "def DB_Connection(HOST = HOST, PORT = PORT, DB_ID = DB_ID, DB_PW = DB_PW) :\n",
    "    conn=dbapi.connect(HOST,PORT,DB_ID,DB_PW)\n",
    "    return conn\n",
    "\n",
    "def init_connection() :\n",
    "    \n",
    "    engine = create_engine(f'hana+hdbcli://{DB_ID}:{DB_PW}@{HOST}:{PORT}/', echo = False)\n",
    "    conn = engine.connect()\n",
    "        \n",
    "    return (conn, engine)    \n",
    "\n",
    "def schema_inspector() :\n",
    "    \n",
    "    from sqlalchemy import inspect\n",
    "    \n",
    "    conn, engine = init_connection()\n",
    "    inspector = inspect(engine)\n",
    "    schemas = inspector.get_schema_names()\n",
    "    \n",
    "    conn.close()\n",
    "    engine.dispose()\n",
    "    print(schemas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:35:01.043555Z",
     "start_time": "2021-03-15T01:35:01.039288Z"
    }
   },
   "outputs": [],
   "source": [
    "path = cfg['Recommender']['MODEL_DIR_DEV'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:35:03.516109Z",
     "start_time": "2021-03-15T01:35:03.499434Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def add_log(module_nm, module_type_nm, step, query_type, target_table, start_time) : \n",
    "    \n",
    "    global em\n",
    "    if type(start_time) is float :\n",
    "        start_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    else: \n",
    "        start_time = start_time\n",
    "    print(f'\\n query_type : {query_type} \\n target_table : {target_table.lower()} \\n target_date : {target_date}')\n",
    "    tbl_name = 'tb_amt_campaign_anl_log' \n",
    "    target_table = target_table.lower()\n",
    "    \n",
    "    st = start_time\n",
    "    end_time = datetime.datetime.now()\n",
    "    et = end_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"\"\"\\n start_time : {st} \\n end_time : {et} \\n\"\"\")\n",
    "    print(\"=======================================================================================\")\n",
    "    \n",
    "    try : \n",
    "        print(em)\n",
    "        if em != None :\n",
    "            error_code = 1\n",
    "            error_state = em\n",
    "        else :\n",
    "            error_code = 0\n",
    "            error_state = None\n",
    "    except : \n",
    "        error_code = 0\n",
    "        error_state = None\n",
    "    \n",
    "    res = [module_nm, module_type_nm, step, query_type, target_table, target_date, \n",
    "           st, et, error_code, error_state]\n",
    "    res = pd.DataFrame(res, index = ['module','module_type','step','query_type','target_table','target_date',\n",
    "                                     'start_time','end_time','error_code','error_state']).T\n",
    "\n",
    "    conn, engine = init_connection()\n",
    "    res.to_sql(tbl_name, schema = DB_ID.lower(), con = engine, index = False, if_exists = 'append',\n",
    "               dtype = {'module': types.NVARCHAR(50),\n",
    "                        'module_type': types.NVARCHAR(50),\n",
    "                        'step': types.NVARCHAR(100),\n",
    "                        'query_type': types.NVARCHAR(50),\n",
    "                        'target_table': types.NVARCHAR(200),\n",
    "                        'target_date': types.DATE,\n",
    "                        'start_time': types.NVARCHAR(40),\n",
    "                        'end_time': types.NVARCHAR(40),\n",
    "                        'error_code': types.DECIMAL(2),\n",
    "                        'error_state': types.NVARCHAR(200)\n",
    "                       })\n",
    "    conn.close()\n",
    "    engine.dispose()\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "    return (start_time) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Part "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:40:21.374958Z",
     "start_time": "2021-03-15T01:40:21.369162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-15 10:40:21\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:35:32.818801Z",
     "start_time": "2021-03-15T01:35:32.802504Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def worker(a) :\n",
    "    key_list = list(flt_condition)\n",
    "    a = \"'\"+a+\"'\" \n",
    "\n",
    "    if flt_type == 'default' :\n",
    "        query_main = f\"\"\" SELECT * FROM  {db_name} WHERE {key_variable} = {a} \"\"\"\n",
    "    \n",
    "    elif flt_type == 'cat' :\n",
    "        query_main = f\"\"\" \n",
    "        SELECT * FROM {db_name} \n",
    "        WHERE ({key_list[0]} = {flt_condition[key_list[0]]} and {key_list[1]} = {flt_condition[key_list[1]]})     \n",
    "                AND {key} = {a} \"\"\"\n",
    "    \n",
    "    else : \n",
    "        flt = [\"'\" + x + \"'\" for x in list(flt_condition.values())]\n",
    "        query_main = f\"\"\"\n",
    "        SELECT * FROM {db_name} \n",
    "        WHERE ({flt_var} >= {flt[0]} and {flt_var} <= {flt[1]})     \n",
    "                AND {key} = {a} \"\"\"\n",
    "        \n",
    "    conn = DB_Connection()\n",
    "    result = pd.read_sql(query_main, conn)\n",
    "    conn.close()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def Datachunk_range(key_variable) :\n",
    "    key_list = list(flt_condition)\n",
    "    \n",
    "    if flt_type == 'default' :\n",
    "        query_arg = f\" SELECT distinct {key_variable} FROM {db_name} \"\n",
    "    \n",
    "    elif flt_type == 'cat' :\n",
    "        query_arg = f\"\"\" \n",
    "        SELECT distinct {key_variable} FROM {db_name} \n",
    "        WHERE ({key_list[0]} = {flt_condition[key_list[0]]} and {key_list[1]} = {flt_condition[key_list[1]]}) \n",
    "        \"\"\"\n",
    "    else : \n",
    "        flt = [\"'\" + x + \"'\" for x in list(flt_condition.values())]\n",
    "        query_arg = f\"\"\" \n",
    "        SELECT distinct {key_variable} FROM {db_name} \n",
    "        WHERE ({flt_var} >= {flt[0]} and {flt_var} <= {flt[1]})     \n",
    "        \"\"\"\n",
    "    conn = DB_Connection()\n",
    "    arg_list = pd.read_sql(query_arg, conn)\n",
    "    \n",
    "    arg_list = arg_list.iloc[:,0].values.tolist()\n",
    "    arg_list_flt = [arg_list[i] for i in range(len(arg_list)) if arg_list[i] != None] ## None 타입 제외\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    return arg_list_flt\n",
    "\n",
    "def multiprocesser() : \n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    arg_list = Datachunk_range(key_variable = key)\n",
    "    \n",
    "    if __name__ == '__main__' : \n",
    "        p = multiprocessing.Pool(processes = n_core)\n",
    "        data = p.map(worker, arg_list) \n",
    "        p.terminate() ## Close a pipe which informs readers of that pipe\n",
    "        p.join() ## Wait for a child process to be killed\n",
    "        \n",
    "        time.sleep(10)\n",
    "        del p\n",
    "    \n",
    "    result = pd.concat(data)\n",
    "    time.sleep(10)\n",
    "    \n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "          f\" || {db_name} Data Loading is completed.\",\n",
    "          \"(elapsed time :\", np.round((time.time() - start_time) / 60, 2), \"mins)\")\n",
    "    \n",
    "    return result   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:35:33.224231Z",
     "start_time": "2021-03-15T01:35:33.208367Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## ---------------------------------------\n",
    "## Data 정제 Function (일별 배치용)\n",
    "## ---------------------------------------\n",
    "def data_preparation(df) : \n",
    "    \n",
    "    start_time = time.time()\n",
    "    ratings = df[['CUST_ID','PRDT_DCODE_CD','DT_CNT','SUM_QTY']]\n",
    "\n",
    "    ## TF Transformation\n",
    "    tf, idf, tfidf = tf_idf_matrix(df)\n",
    "\n",
    "    ## Product Mapping\n",
    "    prdt_cd = list(df['PRDT_DCODE_CD'].unique())\n",
    "    prdt_cd_df = prdt_map[prdt_map['PRDT_DCODE_CD'].isin(prdt_cd)].sort_values(by = 'PRDT_DCODE_CD', ascending = True)\n",
    "\n",
    "    ## Corpus 생성\n",
    "    corpus = tf.apply(row_to_tuple, mst = prdt_cd_df, axis = 1)\n",
    "    \n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "          \" || Data Preprocessing is completed.\",\n",
    "          \"(elapsed time :\", np.round((time.time() - start_time) / 60, 2), \"mins)\")\n",
    "    \n",
    "    return prdt_cd_df, tf, corpus\n",
    "\n",
    "def row_to_tuple(a, mst) : \n",
    "    a_flt = a[a > 0]\n",
    "    a_list = a_flt.index.tolist()\n",
    "    \n",
    "    c = mst.PRDT_DCODE_CD \n",
    "    c = c[c.isin(a_list)].index.tolist()\n",
    "\n",
    "    return list(zip(c,a_flt.tolist()))\n",
    "\n",
    "def tf_idf_matrix(df) :\n",
    "    \n",
    "    ## document length\n",
    "    N = len(df['CUST_ID'].unique())\n",
    "    \n",
    "    ## TF Matrix 변환 \n",
    "    tf = pd.pivot_table(df, values = 'DT_CNT', index = 'CUST_ID', columns = 'PRDT_DCODE_CD')\n",
    "    tf = tf.fillna(0)\n",
    "    \n",
    "    ## IDF Matrix 계산 \n",
    "    idf = df.groupby(['PRDT_DCODE_CD']).sum()['DT_CNT']\n",
    "    idf = np.log((N+1)/(idf + 1)) + 1\n",
    "    \n",
    "    # TF-IDF Matrix 계산\n",
    "    tfidf = tf.mul(idf)\n",
    "    \n",
    "    # L2 정규화 Term\n",
    "    tfidf.iloc[:,:] = Normalizer(norm = 'l2').fit_transform(tfidf)\n",
    "        \n",
    "    print(\"          Total customer number on\",target_date,\"is :\",N)\n",
    "    print(\"          tf.shape :\",tf.shape, \n",
    "          \"idf.shape :\",idf.shape, \"tfidf.shape :\", tfidf.shape)\n",
    "    \n",
    "    return tf, idf, tfidf    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최신일자 파일 찾아오는 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:35:33.698681Z",
     "start_time": "2021-03-15T01:35:33.691876Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def file_search(file_dir, pattern) : \n",
    "    files = os.listdir(file_dir)\n",
    "    p = re.compile(pattern) \n",
    "\n",
    "    f_list = []\n",
    "    for f in files : \n",
    "        out = p.match(f)\n",
    "        if out != None : f_list.append(f)\n",
    "        else : pass\n",
    "    f_list = np.sort(f_list) ## 오름차 순으로 Sorting\n",
    "    return f_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 개발 일자 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:35:35.232574Z",
     "start_time": "2021-03-15T01:35:35.221312Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## (20.12.25 update)\n",
    "## 모델이 매월 첫째 주 주말 토요일이면 업데이트 진행되도록 로직 설정\n",
    "## 현업과 사전 협의가 필요한 부분. \n",
    "## 1. 어느 서버를 사용할 것인지\n",
    "## 2. 사전에 몇 일치 데이터가 적재되어 있어야 함\n",
    "\n",
    "## (21.01.18 update)\n",
    "## 모델 업데이트 주기가 확정되면 반영 예정\n",
    "\n",
    "def model_update_interpreter(model_dev_start_date) : \n",
    "    \"\"\"\n",
    "    계산로직\n",
    "    ---------\n",
    "    model_dev_start_date 를 입력 시, \n",
    "    첫째 주 주말 토요일의 week_no를 계산하고, model_dev_start_date 의 week_no 와 비교    \n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    Y, N 을 리턴\n",
    "    \"\"\"\n",
    "    ## -----------------------------------\n",
    "    weekday_seq = 5 ## 토요일로 가정\n",
    "    ## -----------------------------------\n",
    "    \n",
    "    reformed_target_date = datetime.datetime.strptime(model_dev_start_date,'%Y-%m-%d')\n",
    "    \n",
    "    year = reformed_target_date.year\n",
    "    month = reformed_target_date.month\n",
    "    last_day_of_month = calendar.monthrange(year,month)[1]\n",
    "    \n",
    "    weekday_of_target_date = reformed_target_date.weekday() \n",
    "    week_of_target_date = reformed_target_date.strftime(\"%V\")\n",
    "\n",
    "    isoweek_list = []\n",
    "    for d in range(1,last_day_of_month+1) :\n",
    "        date_iter =  datetime.datetime(year,month,d)\n",
    "        week_no = date_iter.strftime(\"%V\") ## ISO-WEEK 추출\n",
    "        if week_no not in isoweek_list :\n",
    "            if date_iter.weekday() == weekday_seq : # 토요일 가정\n",
    "                isoweek_list += [week_no]\n",
    "        else :\n",
    "            d += 1\n",
    "\n",
    "    isoweek_list = np.sort([int(i) for i in isoweek_list])\n",
    "    \n",
    "    if int(week_of_target_date) == isoweek_list[0] and weekday_of_target_date == weekday_seq :\n",
    "        return_value = \"Y\"\n",
    "        # print(f\">> It's time to update the model as today {model_dev_start_date} is the first weekend of this month.\")\n",
    "    else :\n",
    "        return_value = \"N\"\n",
    "        # print(f\">> Today {model_dev_start_date} is not the assigned date.\")\n",
    "    \n",
    "    return return_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:00:10.953353Z",
     "start_time": "2021-03-15T01:00:10.942821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_update_interpreter(model_dev_start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 여기서 Y 면 if 문으로 모델 fitting & update 하는 로직 구현\n",
    "flag = model_update_interpreter(model_dev_start_date)\n",
    "\n",
    "if (flag == 'Y') | (manual_update == 'y') :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상품 마스터 정제 & 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:57:56.818911Z",
     "start_time": "2021-03-15T01:57:30.966486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-15 10:57:56  || CDS_DW.TB_DW_PRDT_DCODE_CD Data Loading is completed. (elapsed time : 0.43 mins)\n"
     ]
    }
   ],
   "source": [
    "## ------------------------------------\n",
    "## Setting for multiprocessing\n",
    "## ------------------------------------\n",
    "\n",
    "db_name = 'CDS_DW.TB_DW_PRDT_DCODE_CD' ## target DB \n",
    "n_core = 2\n",
    "\n",
    "## multiprocessing 을 위한 arg list\n",
    "key = 'PRDT_CAT_CD'\n",
    "\n",
    "## filter variable\n",
    "flt_type = 'cat'\n",
    "flt_condition = {'AFLCO_CD':'001','BIZTP_CD':'10'}\n",
    "\n",
    "prdt_mst = multiprocesser() \n",
    "# multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:58:19.165790Z",
     "start_time": "2021-03-15T01:58:18.536571Z"
    }
   },
   "outputs": [],
   "source": [
    "## ---------------------------------------\n",
    "## 상품 단어사전 (id2word) 만들기\n",
    "## ---------------------------------------\n",
    "prdt_map = prdt_mst[['PRDT_DCODE_CD','PRDT_DCODE_NM']]\n",
    "prdt_map['row_id'] = range(len(prdt_map))\n",
    "prdt_map = prdt_map.set_index('row_id')\n",
    "\n",
    "id2word = prdt_map[['PRDT_DCODE_NM']].to_dict()['PRDT_DCODE_NM']\n",
    "\n",
    "## ---------------------------------------\n",
    "## prdt_map, id2word 저장 \n",
    "## ---------------------------------------\n",
    "master_file_nm = f'product_master_dict_{target_date_6digits}.pkl'\n",
    "a_file = open(path + master_file_nm, \"wb\")\n",
    "pickle.dump(id2word, a_file)\n",
    "a_file.close()\n",
    "\n",
    "prdt_map.to_csv(path + f'prdt_mst_{target_date_6digits}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:58:23.331882Z",
     "start_time": "2021-03-15T01:58:23.300327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-15 10:58:23  || Chosen the latest id2word is: product_master_dict_210310.pkl\n",
      "2021-03-15 10:58:23  || Chosen the latest product master is: prdt_mst_210310.csv\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------\n",
    "## id2word 불러오기\n",
    "## ---------------------------------------\n",
    "id2word_list = file_search(file_dir = path, pattern = '^product_master_dict_[0-9]+[\\.]pkl$')\n",
    "id2word_target_nm = id2word_list[-1]\n",
    "a_file = open(path + id2word_target_nm, \"rb\")\n",
    "id2word = pickle.load(a_file)\n",
    "\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "      \" || Chosen the latest id2word is:\",id2word_target_nm)\n",
    "\n",
    "## ---------------------------------------\n",
    "## 상품 마스터 불러오기 (product master)\n",
    "## ---------------------------------------\n",
    "prdt_mst_list = file_search(file_dir = path, pattern = \"^prdt_mst_[0-9]+[\\.]csv$\")\n",
    "prdt_mst_target_nm = prdt_mst_list[-1] # Max 값으로 지정. 가장 최신 일자 모델을 끌고 옴\n",
    "prdt_map = pd.read_csv(path + prdt_mst_target_nm)\n",
    "\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "      \" || Chosen the latest product master is:\",prdt_mst_target_nm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:58:26.842776Z",
     "start_time": "2021-03-15T01:58:26.837711Z"
    }
   },
   "outputs": [],
   "source": [
    "## --------------------------------------------------------\n",
    "## multiprocessing 준비\n",
    "\n",
    "db_name = 'CDS_AMT.TB_AMT_RECMD_TMPR' ## target DB \n",
    "n_core = n_worker # 10\n",
    "\n",
    "## data chuck arg 를 위한 기준 변수\n",
    "key = 'PRDT_CAT_CD'\n",
    "\n",
    "## filter date\n",
    "flt_type = 'date'\n",
    "flt_var ='ANL_DT'\n",
    "## --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:05:44.052832Z",
     "start_time": "2021-03-15T01:02:06.377385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-15 10:05:41  || CDS_AMT.TB_AMT_RECMD_TMPR Data Loading is completed. (elapsed time : 3.59 mins)\n"
     ]
    }
   ],
   "source": [
    "flt_condition = {'from':target_date,'to':target_date} ## 일별 배치를 가정\n",
    "df_raw = multiprocesser() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T00:56:49.366063Z",
     "start_time": "2021-03-15T00:56:48.988996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " query_type : Pre-processing \n",
      " target_table : data loading \n",
      " target_date : 2021-03-07\n",
      "\n",
      " start_time : 2021-03-15 09:51:03 \n",
      " end_time : 2021-03-15 09:56:48 \n",
      "\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "start_time = add_log(module_nm = '상품추천', module_type_nm = '개발', \n",
    "                     step = '1.pre-processing', query_type = 'Pre-processing', \n",
    "                     target_table = 'data loading', start_time = start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:15:58.704046Z",
     "start_time": "2021-03-15T01:06:30.984870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Total customer number on 2021-03-07 is : 522366\n",
      "          tf.shape : (522366, 2916) idf.shape : (2916,) tfidf.shape : (522366, 2916)\n",
      "2021-03-15 10:15:56  || Data Preprocessing is completed. (elapsed time : 9.15 mins)\n"
     ]
    }
   ],
   "source": [
    "df_flt = df_raw[['CUST_ID','ANL_DT','PRDT_DCODE_CD','DT_CNT','SUM_QTY']]\n",
    "prdt_df, tf, corpus = data_preparation(df_flt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T05:29:18.391863Z",
     "start_time": "2021-01-27T05:29:18.220596Z"
    }
   },
   "outputs": [],
   "source": [
    "start_time = add_log(module_nm = '상품추천', module_type_nm = '개발', \n",
    "                     step = '1.pre-processing', query_type = 'Pre-processing', \n",
    "                     target_table = 'data transformation (input > corpus)', start_time = start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T14:07:27.762670Z",
     "start_time": "2021-01-25T14:07:27.756072Z"
    }
   },
   "source": [
    "### 초도 모델 Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:14:04.741352Z",
     "start_time": "2021-03-15T02:14:04.736054Z"
    }
   },
   "outputs": [],
   "source": [
    "## LOG PATH 는 CONFIG.INI 에서 별도로 세팅\n",
    "log_path = cfg['Recommender']['DEV_LOG'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:14:08.479073Z",
     "start_time": "2021-03-15T02:14:08.472466Z"
    }
   },
   "outputs": [],
   "source": [
    "log_file_nm = 'lda_model_creation_from_' + target_date_6digits + '.log'\n",
    "logging.basicConfig(filename = log_path + log_file_nm, format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T10:21:46.113458Z",
     "start_time": "2021-01-16T02:07:26.872552Z"
    }
   },
   "outputs": [],
   "source": [
    "## ------------------------------------------------\n",
    "## 모델 초도 개발 함수 \n",
    "## ArgParse 에서 설정한 n_worker, n_pass 적용\n",
    "## ------------------------------------------------\n",
    "lda_model_init = gensim.models.ldamulticore.LdaMulticore(workers = n_worker, # 40 \n",
    "                                                         random_state = 1243,\n",
    "                                                         corpus = corpus, id2word = id2word, \n",
    "                                                         num_topics = 100,\n",
    "                                                         chunksize = 5000, eval_every = 1, \n",
    "                                                         passes = n_pass, # 30 \n",
    "                                                         per_word_topics = True) ## 100, 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = add_log(module_nm = '상품추천', module_type_nm = '개발', \n",
    "                     step = '2.초도 모델 학습', query_type = 'Fitting', \n",
    "                     target_table = 'init model fitting', start_time = start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T10:21:47.570779Z",
     "start_time": "2021-01-16T10:21:47.556191Z"
    }
   },
   "outputs": [],
   "source": [
    "## 초도 개발 Model 저장\n",
    "lda_init_nm = 'lda_model_' + target_date_6digits + '.model'\n",
    "lda_model_init.save(path + lda_init_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ■ ========== TEST ================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:36:36.928105Z",
     "start_time": "2021-03-15T01:36:36.905242Z"
    }
   },
   "outputs": [],
   "source": [
    "## lda _model load\n",
    "## tatget_date\n",
    "\n",
    "current_date = '2021-03-12'\n",
    "target_date = '2021-03-07'\n",
    "training_days = 3\n",
    "n_worker = 20\n",
    "n_pass = 30\n",
    "\n",
    "model_list = file_search(file_dir = path, pattern = \"^lda_model_[0-9]+[\\.]model$\")\n",
    "model_target_nm = model_list[-1] # Max 값으로 지정. 가장 최신 일자 모델을 끌고 옴\n",
    "lda_model_init = LdaModel.load(path + model_target_nm) \n",
    "lda_init_nm =model_target_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:38:52.802683Z",
     "start_time": "2021-03-15T01:38:44.618502Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_nm_list =  file_search(file_dir = path, pattern = \"^corpus_[0-9]+[\\.]pkl$\")\n",
    "a_file = open(path + str(corpus_nm_list[0]), \"rb\")\n",
    "corpus = pickle.load(a_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ■ ==== 원래코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:39:11.085274Z",
     "start_time": "2021-03-15T01:38:56.930151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.4171043504010825\n"
     ]
    }
   ],
   "source": [
    "cm_init = CoherenceModel(model = lda_model_init, corpus = corpus, coherence = 'u_mass')   \n",
    "u_mass_score = cm_init.get_coherence() \n",
    "print(u_mass_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:16:53.842482Z",
     "start_time": "2021-03-15T01:16:41.753050Z"
    }
   },
   "outputs": [],
   "source": [
    "## Corpus 저장\n",
    "# corpus_file_nm = 'corpus_' + target_date_6digits + '.pkl'\n",
    "# corpus_file = open(path + corpus_file_nm, \"wb\")\n",
    "# pickle.dump(corpus, corpus_file)\n",
    "# corpus_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 업데이트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:40:39.732264Z",
     "start_time": "2021-03-15T01:40:39.717000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': '2021-03-08', 'to': '2021-03-08'},\n",
       " {'from': '2021-03-09', 'to': '2021-03-09'},\n",
       " {'from': '2021-03-10', 'to': '2021-03-10'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 기간 설정\n",
    "\n",
    "start_date = datetime.datetime.strptime(target_date, '%Y-%m-%d') + timedelta(days = 1)\n",
    "end_date = datetime.datetime.strptime(target_date, '%Y-%m-%d') + timedelta(days = training_days)\n",
    "step = datetime.timedelta(days=1)\n",
    "\n",
    "date_list = []\n",
    "while start_date <= end_date:\n",
    "    date_list.append(start_date.strftime('%Y-%m-%d'))\n",
    "    start_date += step\n",
    "    \n",
    "## dictionary 형태로 변형\n",
    "day_dict = []\n",
    "for i in date_list :\n",
    "    day_dict += [{'from':i, 'to':i}]\n",
    "    \n",
    "display(day_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T13:27:43.577820Z",
     "start_time": "2021-03-15T02:14:20.417899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " query_type : Update \n",
      " target_table : 1th iterative process : model update on 2021-03-08 \n",
      " target_date : 2021-03-07\n",
      "\n",
      " start_time : 2021-03-15 11:12:43.678032 \n",
      " end_time : 2021-03-15 22:27:05 \n",
      "\n",
      "=======================================================================================\n",
      "calculation time for model update is : 674.37 mins\n",
      "Coherence Score is : -2.953902283617891\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'float' and 'datetime.datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-d0594b59534e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mcm_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_nm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_mass_score\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"calculation time for loop in dt={dt} is :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"mins\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-----------------------------------------------------------------'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'datetime.datetime'"
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "cm_list = []\n",
    "cm_list.append([lda_init_nm,u_mass_score])\n",
    "\n",
    "for k,j in enumerate(day_dict) : \n",
    "    \n",
    "    start_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(j)\n",
    "    \"\"\"\n",
    "    Step 1.\n",
    "    시간 필터링을 통하여 df 를 말아 올림\n",
    "    \"\"\"\n",
    "    flt_condition = j # 시간 filtering condition \n",
    "    df = multiprocesser()\n",
    "    \n",
    "    date_value = list(j.values())[0]\n",
    "    start_time = add_log(module_nm = '상품추천', module_type_nm = '개발', \n",
    "                     step = '3.모델 업데이트', query_type = 'Update', \n",
    "                     target_table = f'{k+1}th iterative process : data loading on {date_value}', start_time = start_time)\n",
    "\n",
    "    \"\"\"\n",
    "    Step 2. \n",
    "    데이터 정제하여 각종 input 생성\n",
    "        - 모델 업데이트 사용 : corpus 리스트\n",
    "        - 집계에 사용 : tf 정보\n",
    "        - 상품추천 정제에 사용 : prdt_df\n",
    "    \"\"\"\n",
    "    prdt_df, tf, corpus = data_preparation(df)  \n",
    "    \n",
    "    start_time = add_log(module_nm = '상품추천', module_type_nm = '개발', \n",
    "                     step = '3.모델 업데이트', query_type = 'Update', \n",
    "                     target_table = f'{k+1}th iterative process : data transformation to corpus on {date_value}', start_time = start_time)\n",
    "    \n",
    "    \"\"\"\n",
    "    Step 3.\n",
    "    매번 최신 모델을 가져와서 갱신하고, Incremental update 를 시행\n",
    "     >>> 기 개발된 모델 50%, 신규 데이터 50% 의 비율로 업데이트 진행\n",
    "    target_date 를 기점으로 일별로 업데이트하여 해당 날짜로 저장\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    dt = df.ANL_DT.unique()[0].strftime('%y%m%d')\n",
    "    print(dt)\n",
    "    \n",
    "#     ## Corpus 저장\n",
    "#     corpus_file_nm = 'corpus_' + dt + '.pkl'\n",
    "#     corpus_file = open(path + corpus_file_nm, \"wb\")\n",
    "#     pickle.dump(corpus, corpus_file)\n",
    "#     corpus_file.close()\n",
    "    \n",
    "    ## 모델 로딩\n",
    "    m_list = file_search(file_dir = path, pattern = \"^lda_model_[0-9]+[\\.]model$\")\n",
    "    model_target_nm = m_list[-1] # Max 값으로 지정. 가장 최신 일자 모델을 끌고 옴\n",
    "    lda_model = LdaModel.load(path + model_target_nm) \n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "      \" || Chosen the latest model is:\",model_target_nm)\n",
    "\n",
    "    ## configuration setting ----------------------------------\n",
    "    logging.basicConfig(filename = log_path + log_file_nm, format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    # lda_model.chunksize = 5000\n",
    "    # lda_model.workers = 40\n",
    "    # lda_model.passes = 30\n",
    "    ## --------------------------------------------------------\n",
    "    \n",
    "    lda_model.update(corpus)\n",
    "    model_list.append(lda_model) ## model container 추가\n",
    "    \n",
    "    start_time = add_log(module_nm = '상품추천', module_type_nm = '개발', \n",
    "                     step = '3.모델 업데이트', query_type = 'Update', \n",
    "                     target_table = f'{k+1}th iterative process : model update on {date_value}', start_time = start_time)\n",
    "    print(\"calculation time for model update is :\", np.round((time.time() - start)/60, 2),\"mins\")\n",
    "    \n",
    "    # 모델 저장\n",
    "    save_nm = \"lda_model_\" + dt + \".model\"\n",
    "    lda_model.save(path + save_nm) \n",
    "    \n",
    "    # CM score 확인 \n",
    "    cm_iter = CoherenceModel(model = lda_model, corpus = corpus, coherence = 'u_mass')   \n",
    "    u_mass_score = cm_iter.get_coherence() \n",
    "    print(\"Coherence Score is :\",u_mass_score)\n",
    "    cm_list.append([save_nm, u_mass_score])\n",
    "    \n",
    "    print(f\"calculation time for loop in dt={dt} is :\", np.round((time.time() - start)/60, 2),\"mins\")\n",
    "    print('\\n','-----------------------------------------------------------------','\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:04:16.399715Z",
     "start_time": "2021-03-16T00:04:16.388004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculation time for loop in dt=210308 is : 1311.55 mins\n"
     ]
    }
   ],
   "source": [
    "print(f\"calculation time for loop in dt={dt} is :\", np.round((time.time() - start)/60, 2),\"mins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최신 파일만 운영 directory 로 import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:05:03.380077Z",
     "start_time": "2021-03-16T00:05:03.372766Z"
    }
   },
   "outputs": [],
   "source": [
    "## 최신 id2word 확인\n",
    "id2word_list = file_search(file_dir = path, pattern = '^product_master_dict_[0-9]+[\\.]pkl$')\n",
    "id2word_target_nm = id2word_list[-1]\n",
    "\n",
    "## 최신 마스터 확인 (product master)\n",
    "prdt_mst_list = file_search(file_dir = path, pattern = \"^prdt_mst_[0-9]+[\\.]csv$\")\n",
    "prdt_mst_target_nm = prdt_mst_list[-1] # Max 값으로 지정. 가장 최신 일자 모델을 끌고 옴\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:05:06.176733Z",
     "start_time": "2021-03-16T00:05:06.173772Z"
    }
   },
   "outputs": [],
   "source": [
    "f_list = [id2word_target_nm] + [prdt_mst_target_nm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:05:08.511730Z",
     "start_time": "2021-03-16T00:05:08.502279Z"
    }
   },
   "outputs": [],
   "source": [
    "## 최신 LDA 모델 확인 \n",
    "ftype_list = ['model','model.expElogbeta.npy','model.id2word','model.state']\n",
    "\n",
    "model_target_ftype_list = []\n",
    "for ftype in ftype_list : \n",
    "    m_list =  file_search(file_dir = path, pattern = f\"^lda_model_[0-9]+[\\.]{ftype}$\")\n",
    "    m_target_file =  m_list[-1]\n",
    "    model_target_ftype_list += [m_target_file] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:05:10.886914Z",
     "start_time": "2021-03-16T00:05:10.884904Z"
    }
   },
   "outputs": [],
   "source": [
    "f_list += model_target_ftype_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:05:13.170735Z",
     "start_time": "2021-03-16T00:05:13.167620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-16 09:05:13|| These model files are copied and moved into opt location :\n",
      "\n",
      "product_master_dict_210310.pkl\n",
      "prdt_mst_210310.csv\n",
      "lda_model_210308.model\n",
      "lda_model_210308.model.expElogbeta.npy\n",
      "lda_model_210308.model.id2word\n",
      "lda_model_210308.model.state\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "      \"|| These model files are copied and moved into opt location :\\n\\n\",'\\n'.join(f_list),'\\n', sep = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:05:15.508731Z",
     "start_time": "2021-03-16T00:05:15.497578Z"
    }
   },
   "outputs": [],
   "source": [
    "## --------------------------------------------\n",
    "## 이관 디렉토리 설정 \n",
    "\n",
    "# path = cfg['Recommender']['MODEL_DIR_DEV']  # from \n",
    "path2 = cfg['Recommender']['MODEL_DIR'] # to\n",
    "## --------------------------------------------\n",
    "\n",
    "for f in f_list : \n",
    "    shutil.copy2(path + f, path2 + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:05:18.244003Z",
     "start_time": "2021-03-16T00:05:18.078388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " query_type : Copy \n",
      " target_table : model files are copied into oprtn directory \n",
      " target_date : 2021-03-07\n",
      "\n",
      " start_time : 2021-03-15 22:27:05.985268 \n",
      " end_time : 2021-03-16 09:05:18 \n",
      "\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "start_time = add_log(module_nm = '상품추천', module_type_nm = '개발', \n",
    "                     step = '4.운영 디렉토리 이관', query_type = 'Copy', \n",
    "                     target_table = 'model files are copied into oprtn directory', start_time = start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "else : \n",
    "    start_time = add_log(module_nm = '상품추천', module_type_nm = '개발', \n",
    "                         step = '업데이트 일자 확인', query_type = 'terminate', \n",
    "                         target_table = 'pass the update process : not the arranged date', start_time = start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 확인"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "/# ## Path 내에서 가장 최신 모델을 가져옴\n",
    "\n",
    "# model_list = file_search(file_dir = path, pattern = \"^lda_model_[0-9]+[\\.]model$\")\n",
    "# model_target_nm = model_list[-1] # Max 값으로 지정. 가장 최신 일자 모델을 끌고 옴\n",
    "# lda_model_iter = LdaModel.load(path + model_target_nm) \n",
    "\n",
    "# print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "#       \" || Chosen the latest model is:\",model_target_nm)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# lda_model_iter.print_topics(num_topics =100, num_words = 30)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# cm_list = []\n",
    "\n",
    "# corpus_nm_list =  file_search(file_dir = path, pattern = \"^corpus_[0-9]+[\\.]pkl$\")\n",
    "# for c in corpus_nm_list :\n",
    "#     a_file = open(path + c, \"rb\")\n",
    "#     corpus_iter = pickle.load(a_file)\n",
    "    \n",
    "#     model_nm_list =  file_search(file_dir = path, pattern = \"^lda_model_[0-9]+[\\.]model$\")\n",
    "#     for m in model_nm_list : \n",
    "#         lda_model_iter = LdaModel.load(path + m) \n",
    "        \n",
    "#         cm_iter = CoherenceModel(model = lda_model_iter, corpus = corpus_iter, coherence = 'u_mass')   \n",
    "#         u_mass_score = cm_iter.get_coherence() \n",
    "#         print([c,m, u_mass_score])\n",
    "#         cm_list.append([c,m, u_mass_score])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ## reference : https://radimrehurek.com/gensim/auto_examples/howtos/run_compare_lda.html\n",
    "\n",
    "# def plot_difference_plotly(mdiff, title=\"\", annotation=None):\n",
    "#     \"\"\"Plot the difference between models.\n",
    "\n",
    "#     Uses plotly as the backend.\"\"\"\n",
    "#     import plotly.graph_objs as go\n",
    "#     import plotly.offline as py\n",
    "\n",
    "#     annotation_html = None\n",
    "#     if annotation is not None:\n",
    "#         annotation_html = [\n",
    "#             [\n",
    "#                 \"+++ {}<br>--- {}\".format(\", \".join(int_tokens), \", \".join(diff_tokens))\n",
    "#                 for (int_tokens, diff_tokens) in row\n",
    "#             ]\n",
    "#             for row in annotation\n",
    "#         ]\n",
    "\n",
    "#     data = go.Heatmap(z=mdiff, colorscale='RdBu', text=annotation_html)\n",
    "#     layout = go.Layout(width=950, height=950, title=title, xaxis=dict(title=\"topic\"), yaxis=dict(title=\"topic\"))\n",
    "#     py.iplot(dict(data=[data], layout=layout))\n",
    "\n",
    "# def plot_difference_matplotlib(mdiff, title=\"\", annotation=None):\n",
    "#     \"\"\"Helper function to plot difference between models.\n",
    "\n",
    "#     Uses matplotlib as the backend.\"\"\"\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     fig, ax = plt.subplots(figsize=(18, 14))\n",
    "#     data = ax.imshow(mdiff, cmap='RdBu_r', origin='lower')\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar(data)\n",
    "\n",
    "# try:\n",
    "#     get_ipython()\n",
    "#     import plotly.offline as py\n",
    "# except Exception:\n",
    "#     #\n",
    "#     # Fall back to matplotlib if we're not in a notebook, or if plotly is\n",
    "#     # unavailable for whatever reason.\n",
    "#     #\n",
    "#     plot_difference = plot_difference_matplotlib\n",
    "# else:\n",
    "#     py.init_notebook_mode()\n",
    "#     plot_difference = plot_difference_plotly"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ## 기 개발된 model 의 토픽 간 상관성 비교 (m2)\n",
    "\n",
    "# m2 = lda_model_iter\n",
    "# mdiff, annotation = m2.diff(m2, distance='jaccard', num_words=50)\n",
    "# plot_difference(mdiff, title=\"Topic difference (one model) [jaccard distance]\", annotation=annotation)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": "40"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
